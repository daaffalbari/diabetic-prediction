# -*- coding: utf-8 -*-
"""Diabetes Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zcw7HdRXpbQShTpaGjIeQh4kWR6fBjb2

# Proyek Pertama: Predictive Analytics


---

## Data Diri
Nama: Daffa Albari

Email: daffaa.albari@gmail.com

Dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset


Reference:


1.   
[Neighbors](https://scikit-learn.org/stable/modules/neighbors.html)
2.   [Tree](https://scikit-learn.org/stable/modules/tree.html)
3.  [Forest](https://scikit-learn.org/stable/modules/ensemble.html)
"""

!pip install -q kaggle

"""# **1. *Library Import***

*Library* [`os`](https://docs.python.org/3/library/os.html) untuk memproses *function* dari *operating system*. `os.environ` untuk membaca *username* dan *key* [Kaggle](https://kaggle.com).

*Library* [`pandas`](https://pandas.pydata.org) untuk melakukan pemrosesan, analisis dan manipulasi data.

*Library* [`tensorflow`](https://www.tensorflow.org) untuk melakukan pelatihan *machine learning* dan *neural networks*.

*Library* [`sklearn`](https://scikit-learn.org) untuk melakukan pemrosesan *machine learning* dan *data analysis*.

*Library* [`seaborn`](https://seaborn.pydata.org) untuk membuat visualisasi data yang berbasis `matplotlib`.

*Library* [`matplotlib`](https://matplotlib.org/) untuk melakukan visualisasi menggunakan *plotting*.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

from google.colab import files

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, mean_squared_error, f1_score, precision_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

"""# **2. *Data Loading***

## 2.1 *Kaggle Credential and Dataset Download*
"""

files.upload()
!mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d iammustafatz/diabetes-prediction-dataset

! unzip diabetes-prediction-dataset.zip -d diabetes_prediction

path = '/content/diabetes_prediction/diabetes_prediction_dataset.csv'

"""Menampilkan isi dataset menggunakan pandas"""

data = pd.read_csv(path)
data.head()

"""# **3. *Data Understanding***"""

data.columns

"""Pada dataset ini terdapat 9 fitur. Fitur diabetas adalah fitur targetnya. Kita akan mempredeksi apakah seseorang terkena dibetes dari 8 fitur tersebut"""

data.info()

data.isna().sum()

"""Tidak ada missing values pada dataset ini"""

data['diabetes'].value_counts()

data['diabetes'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140)
plt.title('Distribusi Target')
plt.show()

labels = ['Female', 'Male', 'Other']
values = data['gender'].value_counts().values

plt.style.use('fivethirtyeight')
plt.figure(figsize=(10, 8))
plt.subplot(1, 2, 1)
sns.countplot(x=data['gender'], data=data)
plt.subplot(1, 2, 2)
plt.pie(values, labels=labels, autopct='%1.1f%%')
plt.show()

data.describe()

"""Melihat deskripsi statistik dari *dataframe* `diabetes_prediction` yaitu,
1.   `count` : Jumlah data
2.   `mean` : Rata-rata
3.   `std` : Standar deviasi/simpangan baku
4.   `min` : Nilai minimum
5.   `25%` : Kuartil bawah/Q1
6.   `50%` : Kuartil tengah/Q2/median
7.   `75%` : Kuartil atas/Q3
8.   `max` : Nilai maksimum
"""

data.duplicated().sum()

"""Ada beberapa data yang duplicated

## Data Cleaning
"""

data = data.drop_duplicates()

data.shape

fig, axes = plt.subplots(2, 2, figsize=(10, 8))

sns.boxplot(ax=axes[0, 0], x=data.age)
sns.boxplot(ax=axes[0, 1], x=data.bmi)
sns.boxplot(ax=axes[1, 0], x=data.HbA1c_level)
sns.boxplot(ax=axes[1, 1], x=data.blood_glucose_level)

"""Terlihat pada diagram boxplot, terdapat beberapa outlier.

UNtuk mengatasi outlier, dilakukan pendekatan Z-Index.

### Menangani Outlier dengan menggunakan Z-Index

Pengolahan outlier dengan menggunakan z-score atau indeks z adalah salah satu teknik umum yang digunakan untuk mendeteksi dan menangani outlier dalam data. Z-score mengukur sejauh mana setiap titik data berjarak dari rata-rata populasi dalam satuan deviasi standar.

Z_i = (X_i - Mean) / StdDev

Di mana:

*   Z_i adalah z-score untuk titik data ke-i.
*   X_i adalah nilai titik data ke-i.
*   Mean adalah rata-rata (mean) dari seluruh data.
*   StdDev adalah deviasi standar dari seluruh data.
"""

test = data[['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']]
z = np.abs(stats.zscore(test))
data = data[(z < 3).all(axis=1)]

data.shape

data.head()

"""## Exploratory Data Analysis - Univariate Analysis"""

categorical_features = ['gender', 'hypertension', 'heart_disease', 'smoking_history']
numerical_features = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']

"""### Categorical Features"""

feature = categorical_features[0]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)

df = pd.DataFrame({'Jumlah sample': count, 'Persentasi':percent.round(1)})
print(df)

"""Jumlah jenisi kelamin other sangat sedikit"""

count.plot(kind='bar', title='Feature')

feature = categorical_features[1]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)

df = pd.DataFrame({'Jumlah sample': count, 'Persentasi':percent.round(1)})
print(df)

feature = categorical_features[2]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)

df = pd.DataFrame({'Jumlah sample': count, 'Persentasi':percent.round(1)})
print(df)

feature = categorical_features[3]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)

df = pd.DataFrame({'Jumlah sample': count, 'Persentasi':percent.round(1)})
print(df)

count.plot(kind='bar', title='Feature')

"""### Numerical Features"""

data.hist(bins=50, figsize=(20, 15))
plt.show()

"""## Exploratory Data Analysis - Multivariate Analysis

### Categorical Features
"""

cat_features = data.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y='diabetes', kind='bar', dodge=False, height=4, aspect=3, data=data, palette='Set3')
  plt.title('Rata-rata price relatif terhadap - {}'.format(col))

"""### Numerical Features"""

fig=plt.gcf()
fig.set_size_inches(10,8)
plt.title('Correlation Between The Features')
a = sns.heatmap(data.corr(), annot=True, cmap='Pastel1', fmt='.2f', linewidths=0.2)
a.set_xticklabels(a.get_xticklabels(), rotation=60)
a.set_yticklabels(a.get_yticklabels())
plt.show()

"""# **4. *Data Preparation***

### Encoding Fitur Kategori
"""

data.head()

"""categorical_features = ['gender', 'hypertension', 'heart_disease', 'smoking_history']"""

data['smoking_history'].replace({'never': 2, 'No Info': 3, 'current': 4, 'former': 5,
                                'not current': 6, 'ever': 7}, inplace=True)

data['gender'].replace({'Male': 2, 'Female': 3, 'Other': 3}, inplace=True)

"""### Train Test Split"""

X = data.drop(['diabetes'], axis=1)
y = data['diabetes']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

scaler = StandardScaler()

cols = X_train.columns

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])

X_train.head()

X_train.describe().round(4)

"""# **5. *Model Development***"""

def metrics_calculator(y_test, y_pred, model_name):
    '''
    This function calculates all desired performance metrics for a given model.
    '''
    result = pd.DataFrame(data=[accuracy_score(y_test, y_pred),
                                precision_score(y_test, y_pred, average='macro'),
                                recall_score(y_test, y_pred, average='macro'),
                                f1_score(y_test, y_pred, average='macro'),
                                mean_squared_error(y_test, y_pred)],
                          index=['Accuracy','Precision','Recall','F1-score', 'mse'],
                          columns = [model_name])
    return result

models = pd.DataFrame(
    index   = ['train_mse', 'test_mse'],
    columns = ['KNN', 'RandomForest', 'DecisionTree']
)

"""## KNeighbors"""

knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

knn_result = metrics_calculator(y_test, y_pred, 'KNN')
knn_result

models.loc['train_mse', 'knn'] = mean_squared_error(y_pred=knn.predict(X_train), y_true=y_train)

"""## Random Forest"""

rf = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
rf.fit(X_train, y_train)

models.loc['train_mse', 'RandomForest'] = mean_squared_error(y_pred=rf.predict(X_train), y_true=y_train)

y_pred = rf.predict(X_test)

rf_result = metrics_calculator(y_test, y_pred, 'Random Forest')
rf_result

"""## Decision Tree"""

dt = DecisionTreeClassifier(criterion='entropy', max_depth=9)
dt.fit(X_train, y_train)

models.loc['train_mse', 'DecisionTree'] = mean_squared_error(y_pred=dt.predict(X_train), y_true=y_train)

y_pred = dt.predict(X_test)

dt_result = metrics_calculator(y_test, y_pred, 'Decesion Tree')
dt_result

"""# **5. *Evaluation***"""

evaluation_all = pd.concat([dt_result, knn_result, rf_result], axis=1)
evaluation_all

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RandomForest', 'DecisionTree'])

model_dict = {'KNN': knn, 'RandomForest': rf, 'DecisionTree': dt}


for name, model in model_dict.items():
  mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
  mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)